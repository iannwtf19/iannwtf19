{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iannwtf19/iannwtf19/blob/main/Week10/Homework10_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import tqdm\n",
        "import datetime"
      ],
      "metadata": {
        "id": "zeBdznSPTDXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation\n",
        "## Load file\n",
        "First let's mount Google Drive, where we keep our input file (the bible).\n",
        "If you are working locally & don't need Google Drive you may skip this cell.\n",
        "If the file does not exist yet, we will create it."
      ],
      "metadata": {
        "collapsed": false,
        "id": "hsuGm5wHTDXd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN19gJlYTDXf",
        "outputId": "4b54736a-2573-4597-96e5-c1d005d774d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "os.chdir(\"drive/MyDrive/tensorflow\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we download the file if it doesn't already exist.\n",
        "Finally, open and read it."
      ],
      "metadata": {
        "collapsed": false,
        "id": "pROj1h73TDXg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "filename = 'bible.txt'\n",
        "if not os.path.isfile(filename):\n",
        "    urllib.request.urlretrieve('https://raw.githubusercontent.com/iannwtf19/iannwtf19/main/Week10/bible.txt', 'bible.txt')"
      ],
      "metadata": {
        "id": "-swoTK49TDXg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": [
        "# Open input file\n",
        "text_file = open(\"bible.txt\")\n",
        "# Read the text file as a string (a sequence of characters)\n",
        "corpus = text_file.read()"
      ],
      "metadata": {
        "id": "xenDu4_RTDXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what the text looks like"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ZaxFNMNUTDXh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The First Book of Moses:  Called Genesis\n",
            "\n",
            "\n",
            "1:1 In the beginning God created the heaven and the earth.\n",
            "\n",
            "1:2 And the earth was without form, and void; and darkness was upon\n",
            "the face of the deep. And the\n"
          ]
        }
      ],
      "source": [
        "print(corpus[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QFbyBPFTDXh",
        "outputId": "b3f7c817-4ad1-45ee-8564-da72de9c2a59"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization\n",
        "Convert the corpus into sequence of word tokens. Default settings have filters and makes each token lowercase. We give vocab_size as 10000, which will tokenize the most common 10000 words."
      ],
      "metadata": {
        "collapsed": false,
        "id": "vPDC7JQxTDXi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "vocab_size = 10000\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "    num_words=vocab_size,\n",
        "    lower=True,\n",
        "    split=' ',\n",
        "    char_level=False,\n",
        "    analyzer=None\n",
        ")\n",
        "# Generate vocabulary from the corpus\n",
        "tokenizer.fit_on_texts([corpus])\n",
        "# A dictionary of \"word: index\" entries\n",
        "vocab = tokenizer.word_index\n",
        "# Reversed dictionary of \"index: word\" entries, for fetching the word from the index\n",
        "inverse_vocab = {index: token for token, index in vocab.items()}\n",
        "# Just the list of words\n",
        "word_tokens = list(vocab.keys())"
      ],
      "metadata": {
        "id": "IjjZBl9oTDXi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 10 elements of vocabulary: [('the', 1), ('and', 2), ('of', 3), ('to', 4), ('that', 5), ('in', 6), ('he', 7), ('shall', 8), ('unto', 9), ('for', 10)]\n"
          ]
        }
      ],
      "source": [
        "print(f'First 10 elements of vocabulary: {list(vocab.items())[:10]}')"
      ],
      "metadata": {
        "id": "DfyVjaxqTDXj",
        "outputId": "f7554cef-4347-41ba-985c-bcd4bdc853d6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate skip-gram pairs"
      ],
      "metadata": {
        "collapsed": false,
        "id": "KsBnWDJ-TDXj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "corpus_sequences = tokenizer.texts_to_sequences([corpus])\n",
        "window_size = 2\n",
        "# Generate sampling table for subsampling\n",
        "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
        "# Generate tuples of (target_word_index, context_word_index) for the most common 10000 words\n",
        "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
        "    corpus_sequences[0],\n",
        "    vocabulary_size=vocab_size,\n",
        "    window_size=window_size,\n",
        "    sampling_table=sampling_table,\n",
        "    negative_samples=0)"
      ],
      "metadata": {
        "id": "QG2cZkrJTDXj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 3220): (o, sir)\n",
            "(26, 511): (was, commandment)\n",
            "(210, 21): (saw, it)\n",
            "(2861, 194): (star, time)\n",
            "(410, 97): (prophets, let)\n"
          ]
        }
      ],
      "source": [
        "# Print some positive samples\n",
        "for target, context in positive_skip_grams[:5]:\n",
        "    print(f\"({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})\")"
      ],
      "metadata": {
        "id": "ybw8hr5JTDXk",
        "outputId": "1a73e6a8-7795-4c88-dc0a-879673cbdc0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate dataset"
      ],
      "metadata": {
        "collapsed": false,
        "id": "yzrxFvNDTDXk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "batch_size = 256\n",
        "skipgram_array = np.array(positive_skip_grams)\n",
        "# Convert [target_word_index, context_word_index] into tuples of (target_word_index, context_word_index)\n",
        "target_index_slices = skipgram_array[:, 0]\n",
        "context_index_slices = skipgram_array[:, 1]\n",
        "skipgram_ds = tf.data.Dataset.from_tensor_slices((target_index_slices, context_index_slices))\n",
        "skipgram_ds = skipgram_ds.cache().shuffle(10000).batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "fDBqg_AXTDXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the model\n",
        "## NCE Layer\n",
        "First we define a layer that will compute the NCE loss. This layer will be called to get the loss."
      ],
      "metadata": {
        "collapsed": false,
        "id": "yvUKwTByTDXk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class NCELayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, embedding_size, num_neg_samples):\n",
        "        super(NCELayer, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.num_neg_samples = num_neg_samples\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # initialize weights and biases\n",
        "        self.nce_weights = self.add_weight(\n",
        "            name=\"nce_weights\",\n",
        "            shape=(self.vocab_size, self.embedding_size),\n",
        "            initializer=\"glorot_normal\",\n",
        "        )\n",
        "\n",
        "        self.nce_bias = self.add_weight(\n",
        "            name=\"nce_biases\", shape=(self.vocab_size,), initializer=\"zeros\"\n",
        "        )\n",
        "        super(NCELayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, data):\n",
        "        # Calculate and return NCE loss\n",
        "        true_classes, embeddings = data\n",
        "\n",
        "        loss = tf.reduce_mean(tf.nn.nce_loss(\n",
        "            self.nce_weights, self.nce_bias, tf.reshape(true_classes, (-1, 1)), embeddings, self.num_neg_samples,\n",
        "            self.vocab_size\n",
        "        ))\n",
        "\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "oTTv_JIzTDXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLP Model\n",
        "The full model with an embedding layer and an NCE layer. The embedding layer will hold the word embeddings."
      ],
      "metadata": {
        "collapsed": false,
        "id": "pRa6ymMDTDXl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class NLPModel(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_size, num_neg_samples, optimizer):\n",
        "        super(NLPModel, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.num_neg_samples = num_neg_samples\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        self.metrics_list = [tf.keras.metrics.Mean(name=\"loss\")]\n",
        "\n",
        "        self.embedding_layer = tf.keras.layers.Embedding(vocab_size, embedding_size, input_length=1)\n",
        "        self.nce_layer = NCELayer(vocab_size, embedding_size, num_neg_samples)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Return embedding vector for a given word index\n",
        "        return self.embedding_layer(inputs)\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        target_word_indices, context_word_indices = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            embeddings = self.embedding_layer(target_word_indices)\n",
        "            loss = self.nce_layer((context_word_indices, embeddings))\n",
        "\n",
        "        # Calculate & apply gradients, update metrics\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "        self.metrics[0].update_state(loss)\n",
        "\n",
        "        return {metric.name: metric.result() for metric in self.metrics}\n",
        "\n",
        "    def validate_step(self, val_indices):\n",
        "        # Get embeddings for the given validation words\n",
        "        val_embeddings = self.embedding_layer(val_indices)\n",
        "        # Normalize embedding matrix for similarity calculation\n",
        "        normalized_val_embeddings = tf.nn.l2_normalize(val_embeddings, 1)\n",
        "\n",
        "        # The full embedding matrix is the weights of the embedding layer\n",
        "        embeddings = self.embedding_layer.get_weights()[0]\n",
        "        # Normalize embedding matrix for similarity calculation\n",
        "        normalized_embeddings = tf.nn.l2_normalize(embeddings, 1)\n",
        "\n",
        "        similarities = tf.matmul(normalized_val_embeddings, normalized_embeddings, transpose_b=True)\n",
        "\n",
        "        return similarities\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return self.metrics_list\n",
        "\n",
        "    def reset_metrics(self):\n",
        "        for metric in self.metrics:\n",
        "            metric.reset_states()"
      ],
      "metadata": {
        "id": "dw0ZDEQgTDXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "collapsed": false,
        "id": "duup7y3tTDXl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def training_loop(ds, model, epochs, test_indices, summary_writer):\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch #{epoch}: \")\n",
        "\n",
        "        for data in tqdm.tqdm(ds):\n",
        "            metrics = model.train_step(data)\n",
        "\n",
        "            with summary_writer.as_default():\n",
        "                for metric in model.metrics:\n",
        "                    tf.summary.scalar(f\"{metric.name}\", metric.result(), step=epoch)\n",
        "\n",
        "        # Print training metrices for the epoch\n",
        "        print([f\"{key}: {value.numpy()}\" for (key, value) in metrics.items()])\n",
        "\n",
        "        model.reset_metrics()\n",
        "\n",
        "        # calculate cosine similarities\n",
        "        k = 5\n",
        "        test_data = tf.constant(test_indices, dtype=tf.int32)\n",
        "        similarities = model.validate_step(test_data).numpy()\n",
        "        for i, word_index in enumerate(test_indices):\n",
        "            word = inverse_vocab[word_index]\n",
        "            similarities_of_word = similarities[i]\n",
        "            # Reverse array to get in descending order & start from 1 to skip the same word (itself)\n",
        "            top_k_indices = np.argsort(-similarities_of_word)[1:k+1]\n",
        "            # Convert top-k word indexes to actual words and print\n",
        "            top_k_words = [inverse_vocab[j] for j in top_k_indices]\n",
        "            print(f'Closest neighbors of {word}: {top_k_words}')"
      ],
      "metadata": {
        "id": "VqH2CoaqTDXl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "def create_summary_writer(config_name):\n",
        "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "    log_path = f\"logs/skipgram/{config_name}/{current_time}\"\n",
        "    summary_writer = tf.summary.create_file_writer(log_path)\n",
        "\n",
        "    return summary_writer"
      ],
      "metadata": {
        "id": "cyhxcIsKTDXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "collapsed": false,
        "id": "6hpSsOOzTDXl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch #0: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1407 [00:00<?, ?it/s]2023-02-13 20:37:40.774881: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
            "100%|██████████| 1407/1407 [00:21<00:00, 64.98it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss: 21.354496002197266']\n",
            "Closest neighbors of holy: ['also', 'fire', 'men', 'moses', 'they']\n",
            "Closest neighbors of father: ['these', '27', 'neither', 'my', '8']\n",
            "Closest neighbors of wine: ['through', 'but', 'heaven', 'cloud', 'who']\n",
            "Closest neighbors of poison: ['own', 'throne', 'before', 'caused', 'sought']\n",
            "Closest neighbors of love: ['let', '13', 'on', 'thine', 'that']\n",
            "Closest neighbors of night: ['cry', 'fear', 'hast', 'faith', 'our']\n",
            "Closest neighbors of day: ['12', 'thy', 'this', 'an', '36']\n",
            "Epoch #1: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:13<00:00, 101.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss: 18.73204231262207']\n",
            "Closest neighbors of holy: ['also', 'jews', 'wilderness', 'fire', 'side']\n",
            "Closest neighbors of father: ['fathers', '27', 'these', '8', '33']\n",
            "Closest neighbors of wine: ['through', 'cloud', 'offered', 'hundred', 'length']\n",
            "Closest neighbors of poison: ['afar', 'selah', 'caesar', 'recorder', 'chamber']\n",
            "Closest neighbors of love: ['own', 'let', 'cast', 'old', 'yet']\n",
            "Closest neighbors of night: ['faith', 'fear', 'even', 'offered', 'strength']\n",
            "Closest neighbors of day: ['earth', 'people', 'name', 'king', 'court']\n",
            "Epoch #2: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:13<00:00, 104.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss: 16.837984085083008']\n",
            "Closest neighbors of holy: ['jews', 'wilderness', 'side', 'sword', 'border']\n",
            "Closest neighbors of father: ['fathers', 'burnt', 'own', '33', 'silver']\n",
            "Closest neighbors of wine: ['through', 'five', 'offered', 'offerings', 'length']\n",
            "Closest neighbors of poison: [\"badgers'\", 'selah', 'pound', 'recorder', 'afar']\n",
            "Closest neighbors of love: ['own', 'prosper', 'wherewith', 'going', 'destroy']\n",
            "Closest neighbors of night: ['strength', 'fear', 'faith', 'trees', 'offered']\n",
            "Closest neighbors of day: ['land', 'law', 'earth', 'king', 'people']\n",
            "Epoch #3: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:12<00:00, 109.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss: 15.496509552001953']\n",
            "Closest neighbors of holy: ['angel', 'east', 'border', 'wilderness', 'jews']\n",
            "Closest neighbors of father: ['fathers', 'chariots', 'strength', 'own', 'righteousness']\n",
            "Closest neighbors of wine: ['through', 'five', 'offered', 'silver', 'beast']\n",
            "Closest neighbors of poison: [\"badgers'\", 'weapons', 'pound', 'selah', 'perdition']\n",
            "Closest neighbors of love: ['wherewith', 'nor', 'prosper', 'lovingkindness', 'yet']\n",
            "Closest neighbors of night: ['shields', 'trees', 'fear', 'strength', 'hittite']\n",
            "Closest neighbors of day: ['law', 'king', 'earth', 'name', 'door']\n",
            "Epoch #4: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:13<00:00, 107.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss: 14.040384292602539']\n",
            "Closest neighbors of holy: ['east', 'jews', 'other', 'river', 'poor']\n",
            "Closest neighbors of father: ['strength', 'chariots', 'fathers', 'anger', 'righteousness']\n",
            "Closest neighbors of wine: ['oil', 'pharisees', 'five', 'beast', 'spoil']\n",
            "Closest neighbors of poison: [\"badgers'\", 'gourd', 'bani', 'mary', 'notwithstanding']\n",
            "Closest neighbors of love: ['wherewith', 'lovingkindness', 'also', 'but', 'or']\n",
            "Closest neighbors of night: ['shields', 'even', 'trees', 'order', 'belly']\n",
            "Closest neighbors of day: ['law', 'month', 'wilderness', 'door', 'morning']\n",
            "Epoch #5: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:14<00:00, 95.84it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss: 12.850244522094727']\n",
            "Closest neighbors of holy: ['fire', 'wine', 'other', 'evening', 'canaanites']\n",
            "Closest neighbors of father: ['strength', 'wrath', 'mother', 'fathers', 'brother']\n",
            "Closest neighbors of wine: ['beast', 'oil', 'pharisees', 'ass', 'houses']\n",
            "Closest neighbors of poison: ['bani', \"badgers'\", 'gourd', 'carved', 'unfruitful']\n",
            "Closest neighbors of love: ['also', 'wherewith', 'caused', 'but', 'forget']\n",
            "Closest neighbors of night: ['order', 'even', 'young', 'trees', 'knowledge']\n",
            "Closest neighbors of day: ['waters', 'morning', 'gentiles', 'lord', 'law']\n",
            "Epoch #6: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:13<00:00, 106.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss: 11.992533683776855']\n",
            "Closest neighbors of holy: ['wine', 'fire', 'goodness', 'corn', 'reubenites']\n",
            "Closest neighbors of father: ['brother', 'mother', 'wrath', 'strength', 'face']\n",
            "Closest neighbors of wine: ['beast', 'ass', 'houses', 'oil', 'pharisees']\n",
            "Closest neighbors of poison: ['bani', 'gall', 'ittai', 'loss', 'gourd']\n",
            "Closest neighbors of love: ['also', 'thought', 'caused', 'scorn', 'forget']\n",
            "Closest neighbors of night: ['order', 'famine', 'giving', 'young', 'knowledge']\n",
            "Closest neighbors of day: ['time', 'morning', 'lord', 'gentiles', 'waters']\n",
            "Epoch #7: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:13<00:00, 102.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss: 11.064269065856934']\n",
            "Closest neighbors of holy: ['fast', 'trees', 'wine', 'lamps', 'corn']\n",
            "Closest neighbors of father: ['mother', 'brother', 'wrath', 'neighbour', 'servant']\n",
            "Closest neighbors of wine: ['shemaiah', 'ass', 'pharisees', 'women', 'beast']\n",
            "Closest neighbors of poison: ['bani', 'unfruitful', 'encouraged', 'declaration', 'gileadites']\n",
            "Closest neighbors of love: ['also', 'thought', 'caused', 'testify', 'wherewith']\n",
            "Closest neighbors of night: ['famine', 'twilight', 'order', 'giving', 'remained']\n",
            "Closest neighbors of day: ['time', 'chaldeans', 'lord', 'morning', 'waters']\n",
            "Epoch #8: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:13<00:00, 105.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss: 10.462347030639648']\n",
            "Closest neighbors of holy: ['fleshhooks', 'lamps', 'babylonians', 'coupling', 'firepans']\n",
            "Closest neighbors of father: ['mother', 'brother', 'neighbour', 'wrath', 'servant']\n",
            "Closest neighbors of wine: ['honey', 'fleshhooks', 'shemaiah', 'women', 'ass']\n",
            "Closest neighbors of poison: ['bani', 'cage', 'lentiles', 'organ', 'keys']\n",
            "Closest neighbors of love: ['also', 'thought', 'caused', 'wherewith', 'formed']\n",
            "Closest neighbors of night: ['order', 'twilight', 'assyrian', 'remained', 'famine']\n",
            "Closest neighbors of day: ['time', 'chaldeans', 'stranger', 'place', 'lord']\n",
            "Epoch #9: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:13<00:00, 104.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss: 9.547640800476074']\n",
            "Closest neighbors of holy: ['fleshhooks', 'spoiler', 'abomination', 'jezreelitess', 'queen']\n",
            "Closest neighbors of father: ['mother', 'brother', 'neighbour', 'wrath', 'servants']\n",
            "Closest neighbors of wine: ['honey', 'trumpeters', 'soothsayers', 'shemaiah', 'dry']\n",
            "Closest neighbors of poison: ['keys', 'lentiles', 'organ', 'grape', 'shimri']\n",
            "Closest neighbors of love: ['also', 'thought', 'wherewith', 'caused', 'direct']\n",
            "Closest neighbors of night: ['twilight', 'fly', 'due', 'gardens', 'hedges']\n",
            "Closest neighbors of day: ['time', 'testimony', 'chaldeans', 'hill', 'word']\n",
            "Epoch #10: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:13<00:00, 106.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss: 9.301558494567871']\n",
            "Closest neighbors of holy: ['spoiler', 'abomination', 'fleshhooks', 'queen', 'windows']\n",
            "Closest neighbors of father: ['brother', 'mother', 'servants', 'wrath', 'head']\n",
            "Closest neighbors of wine: ['honey', 'trumpeters', 'carpenters', 'soothsayers', 'passengers']\n",
            "Closest neighbors of poison: ['keys', 'grape', 'revenue', 'bani', 'argob']\n",
            "Closest neighbors of love: ['also', 'wherewith', 'caused', 'thought', 'acknowledge']\n",
            "Closest neighbors of night: ['due', 'fly', 'remained', 'diligence', 'twilight']\n",
            "Closest neighbors of day: ['time', 'word', 'testimony', 'stranger', 'chaldeans']\n",
            "Epoch #11: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:14<00:00, 97.78it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss: 8.841202735900879']\n",
            "Closest neighbors of holy: ['spoiler', 'abomination', 'disobedient', 'windows', 'gardens']\n",
            "Closest neighbors of father: ['mother', 'brother', 'servants', 'neighbour', 'name']\n",
            "Closest neighbors of wine: ['honey', 'carpenters', 'soothsayers', 'trumpeters', 'wizards']\n",
            "Closest neighbors of poison: ['keys', 'pen', 'barrel', 'barachel', 'fowler']\n",
            "Closest neighbors of love: ['also', 'wherewith', 'acknowledge', 'thought', 'caused']\n",
            "Closest neighbors of night: ['fly', 'due', 'dwellest', 'hedges', 'remained']\n",
            "Closest neighbors of day: ['time', 'testimony', 'stranger', 'word', 'place']\n",
            "Epoch #12: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:14<00:00, 99.48it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss: 8.26272201538086']\n",
            "Closest neighbors of holy: ['spoiler', 'abomination', 'poor', 'windows', 'disobedient']\n",
            "Closest neighbors of father: ['mother', 'brother', 'servants', 'neighbour', 'name']\n",
            "Closest neighbors of wine: ['honey', 'carpenters', 'trumpeters', 'soothsayers', 'wizards']\n",
            "Closest neighbors of poison: ['keys', 'eliam', 'jawbone', 'barrel', 'barachel']\n",
            "Closest neighbors of love: ['also', 'command', 'hear', 'formed', 'acknowledge']\n",
            "Closest neighbors of night: ['famine', 'hedges', 'due', 'fly', 'dwellest']\n",
            "Closest neighbors of day: ['time', 'testimony', 'word', 'stranger', 'place']\n",
            "Epoch #13: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:14<00:00, 98.62it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss: 7.806337356567383']\n",
            "Closest neighbors of holy: ['spoiler', 'poor', 'abomination', 'windows', 'vintage']\n",
            "Closest neighbors of father: ['brother', 'mother', 'servants', 'neighbour', 'name']\n",
            "Closest neighbors of wine: ['wizards', 'carpenters', 'honey', 'ashdod', 'trumpeters']\n",
            "Closest neighbors of poison: ['eliam', 'jawbone', 'keys', 'barrel', 'errors']\n",
            "Closest neighbors of love: ['also', 'command', 'hear', 'acknowledge', 'wherewith']\n",
            "Closest neighbors of night: ['gardens', 'hedges', 'dwellest', 'bethel', 'famine']\n",
            "Closest neighbors of day: ['time', 'testimony', 'word', 'chaldeans', 'trusteth']\n",
            "Epoch #14: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1407/1407 [00:14<00:00, 97.56it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['loss: 7.411426067352295']\n",
            "Closest neighbors of holy: ['spoiler', 'vintage', 'abomination', 'youngest', 'poor']\n",
            "Closest neighbors of father: ['brother', 'mother', 'servants', 'name', 'servant']\n",
            "Closest neighbors of wine: ['wizards', 'madness', 'households', 'lud', 'carpenters']\n",
            "Closest neighbors of poison: ['fowler', 'jawbone', 'eliam', 'wedge', 'navy']\n",
            "Closest neighbors of love: ['also', 'command', 'acknowledge', 'tempt', 'hear']\n",
            "Closest neighbors of night: ['dwellest', 'bethel', 'gardens', 'hedges', 'twilight']\n",
            "Closest neighbors of day: ['time', 'testimony', 'word', 'are', 'remaineth']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# create a tf data set with the indices of our validation words\n",
        "test_words = [\"holy\", \"father\", \"wine\", \"poison\", \"love\", \"night\", \"day\"]\n",
        "test_indices = [vocab[test_word] for test_word in test_words]\n",
        "\n",
        "vocabulary_size = len(vocab)\n",
        "embedding_size = 64\n",
        "epochs = 15\n",
        "num_negative_samples = 4\n",
        "\n",
        "optimizer = tf.optimizers.Adam(0.001)\n",
        "summary_writer = create_summary_writer(config_name=f'RUN')\n",
        "\n",
        "model = NLPModel(optimizer=optimizer,\n",
        "                 embedding_size=embedding_size,\n",
        "                 vocab_size=vocabulary_size,\n",
        "                 num_neg_samples=num_negative_samples)\n",
        "\n",
        "training_loop(skipgram_ds, model, epochs, test_indices, summary_writer)"
      ],
      "metadata": {
        "id": "IyPLxgheTDXl",
        "outputId": "3eb19179-e9d3-48f7-89a5-f931267534c8"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}